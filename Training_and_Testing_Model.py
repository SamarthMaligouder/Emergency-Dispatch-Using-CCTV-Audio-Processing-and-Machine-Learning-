# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WKdrNJ-__RxliVhXtJ8gGytz6pc0ppm7
"""

# --- pip (Colab) ---
# !pip install -q numpy librosa soundfile tqdm scikit-learn tensorflow==2.15.*

import os, json, random, numpy as np
import librosa, soundfile as sf
from tqdm import tqdm

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

# ----------------------- CONFIG -----------------------
DATA_ROOT = "/content/data"     # <-- change if needed
CLASSES = ["help", "save_me", "police"]
SR = 16000
WIN_S = 1.2
N_MELS = 128
KEYWORD_W = 0.8
NOISE_W   = 0.2
TARGET_PER_CLASS = 300          # try 300+ if you have few originals

EPOCHS = 25
BATCH  = 32
EARLY_P = 5
REDUCE_P = 3
MIN_LR = 1e-5

SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)
# ------------------------------------------------------

def list_audio(dirp, exts=(".wav",".mp3",".flac",".ogg")):
    if not os.path.isdir(dirp): return []
    return [os.path.join(dirp,f) for f in os.listdir(dirp)
            if os.path.isfile(os.path.join(dirp,f)) and f.lower().endswith(exts)]

def sanitize_audio(y: np.ndarray) -> np.ndarray:
    y = np.asarray(y, dtype=np.float32)
    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)
    return np.clip(y, -1.0, 1.0)

def fix_length(y: np.ndarray, n: int) -> np.ndarray:
    return y if len(y) >= n else np.pad(y, (0, n - len(y)))[:n]

def safe_logmel(y: np.ndarray, sr: int = SR, n_mels: int = N_MELS) -> np.ndarray:
    EPS = 1e-10
    y = sanitize_audio(y)
    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, power=2.0)
    mel = np.maximum(mel, EPS)
    db = librosa.power_to_db(mel, ref=np.max)
    db = np.nan_to_num(db, nan=-80.0, posinf=0.0, neginf=-80.0)
    return np.clip(db, -80.0, 0.0).astype(np.float32)

def load_noises():
    noise_dir = os.path.join(DATA_ROOT, "background_noise")
    nf = list_audio(noise_dir)
    noises = []
    for f in nf:
        try:
            y, _ = librosa.load(f, sr=SR, mono=True)
            if len(y) > 0: noises.append(y.astype(np.float32))
        except: pass
    if not noises:
        # synthesize simple noise (white + hum + pink-ish) ~30s Ã— 3
        print("No background_noise; synthesizing simple noise...")
        for _ in range(3):
            n = int(SR*30)
            white = np.random.randn(n).astype(np.float32)*0.02
            t = np.arange(n)/SR
            hum = 0.01*np.sin(2*np.pi*60*t).astype(np.float32)
            pink_src = np.cumsum(white); pink_src/= (np.max(np.abs(pink_src))+1e-9)
            noises.append((0.6*white+0.2*hum+0.2*pink_src).astype(np.float32))
    return noises

def build_dataset():
    noises = load_noises()
    X, y = [], []
    tgt_len = int(SR*WIN_S)
    for ci, cname in enumerate(CLASSES):
        src = os.path.join(DATA_ROOT, cname)
        files = list_audio(src)
        if not files:
            raise RuntimeError(f"No files for class {cname} in {src}")
        N = max(TARGET_PER_CLASS, len(files))
        for _ in tqdm(range(N), desc=f"Augment {cname}"):
            f = random.choice(files)
            kw, _ = librosa.load(f, sr=SR, mono=True)
            kw = sanitize_audio(kw)
            if len(kw) > tgt_len:
                s = random.randint(0, len(kw)-tgt_len)
                kw = kw[s:s+tgt_len]
            kw = fix_length(kw, tgt_len)
            nz = random.choice(noises)
            if len(nz) < tgt_len: continue
            s = random.randint(0, len(nz)-tgt_len)
            nz = nz[s:s+tgt_len]
            mix = kw*KEYWORD_W + nz*NOISE_W
            feat = safe_logmel(mix)
            X.append(feat[..., np.newaxis])
            y.append(ci)
    X = np.stack(X, axis=0)
    y = np.array(y, dtype=np.int32)
    return X, y

def build_model(input_shape, num_classes):
    model = Sequential([
        Input(shape=input_shape),
        Conv2D(32,(3,3),activation='relu',padding='same'), BatchNormalization(), MaxPooling2D((2,2)),
        Conv2D(64,(3,3),activation='relu',padding='same'), BatchNormalization(), MaxPooling2D((2,2)),
        Conv2D(128,(3,3),activation='relu',padding='same'), BatchNormalization(), MaxPooling2D((2,2)),
        Flatten(),
        Dense(128, activation='relu'), Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def export_tflite(model, X_train):
    # float
    float_path = "kws_3cls_float.tflite"
    conv = tf.lite.TFLiteConverter.from_keras_model(model)
    open(float_path,"wb").write(conv.convert())
    # int8
    def rep():
        n = min(100, len(X_train))
        for i in range(n):
            yield [X_train[i:i+1].astype(np.float32)]
    int8_path = "kws_3cls_int8.tflite"
    conv = tf.lite.TFLiteConverter.from_keras_model(model)
    conv.optimizations=[tf.lite.Optimize.DEFAULT]
    conv.representative_dataset=rep
    conv.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    conv.inference_input_type=tf.uint8
    conv.inference_output_type=tf.uint8
    open(int8_path,"wb").write(conv.convert())
    print("Saved:", float_path, "and", int8_path)

# -------------------- RUN TRAIN --------------------
print("Building dataset...")
X, y = build_dataset()
Xtr, Xtmp, ytr, ytmp = train_test_split(X, y, test_size=0.25, stratify=y, random_state=SEED)
Xv, Xt, yv, yt = train_test_split(Xtmp, ytmp, test_size=0.5, stratify=ytmp, random_state=SEED)

classes = np.arange(len(CLASSES))
cw = compute_class_weight(class_weight='balanced', classes=classes, y=ytr)
class_weight = {int(c): float(w) for c, w in zip(classes, cw)}
print("class_weight:", class_weight)

model = build_model(Xtr.shape[1:], len(CLASSES))
cbs = [
    EarlyStopping(patience=EARLY_P, restore_best_weights=True, monitor='val_accuracy'),
    ReduceLROnPlateau(patience=REDUCE_P, factor=0.5, min_lr=MIN_LR, monitor='val_loss'),
]
print("Training...")
model.fit(Xtr, ytr, validation_data=(Xv, yv), epochs=EPOCHS, batch_size=BATCH,
          class_weight=class_weight, callbacks=cbs, verbose=1)

print("TEST:", model.evaluate(Xt, yt, verbose=0))

meta = {"classes": CLASSES, "sample_rate": SR, "window_s": WIN_S, "n_mels": N_MELS,
        "input_shape": list(Xtr.shape[1:])}
json.dump(meta, open("kws_3cls_metadata.json","w"), indent=2)

export_tflite(model, Xtr)
print("Done.")

# === Confusion Matrix, Accuracy, Precision, Recall, F1 for kws_3cls_int8.tflite ===
# Run this cell in Colab after uploading:
#   - /content/kws_3cls_int8.tflite
#   - /content/kws_3cls_metadata.json
#   - Test data in /content/test_data/{help,save_me,police}/*.wav

!pip -q install librosa==0.10.1 scikit-learn matplotlib pandas

import os, json, numpy as np, pandas as pd, librosa, matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support
from itertools import product
import tensorflow as tf

MODEL_PATH = "/content/kws_3cls_int8.tflite"
META_PATH  = "/content/kws_3cls_metadata.json"
TEST_ROOT  = "/content/test_data"    # must contain subfolders: help/, save_me/, police/
LIMIT_PER_CLASS = None               # e.g. 200 to cap per-class eval; or None

# ---------- helpers ----------
def list_audio(dirp, exts=(".wav",".mp3",".flac",".ogg",".m4a")):
    return sorted([os.path.join(dirp,f) for f in os.listdir(dirp)
                   if f.lower().endswith(exts)])

def sanitize_audio(y: np.ndarray) -> np.ndarray:
    y = np.asarray(y, dtype=np.float32)
    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)
    return np.clip(y, -1.0, 1.0)

def safe_logmel(y: np.ndarray, sr: int, n_mels: int) -> np.ndarray:
    y = sanitize_audio(y)
    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, power=2.0)
    mel = np.maximum(mel, 1e-10)
    db  = librosa.power_to_db(mel, ref=np.max)
    return np.clip(np.nan_to_num(db, nan=-80.0, posinf=0.0, neginf=-80.0), -80.0, 0.0).astype(np.float32)

def load_spec(fp, sr, win_s, n_mels):
    y, _ = librosa.load(fp, sr=sr, mono=True)
    need = int(sr * win_s)
    if len(y) < need: y = np.pad(y, (0, need - len(y)))
    y = y[:need]
    spec = safe_logmel(y, sr, n_mels)
    return spec[..., np.newaxis]  # (mels, frames, 1)

def ensure_bhwc1(x):
    if x.ndim == 2: x = x[..., np.newaxis]
    if x.ndim == 3: x = x[np.newaxis, ...]
    return x

def quantize_input(x_float, in_det):
    dtype = in_det[0]['dtype']
    scale, zero = in_det[0]['quantization']
    if dtype == np.float32: return x_float.astype(np.float32)
    if not scale: return x_float.astype(dtype)
    return np.round(x_float/scale + zero).astype(dtype)

def dequantize_output(y_quant, out_det):
    dtype = out_det[0]['dtype']
    scale, zero = out_det[0]['quantization']
    if dtype == np.float32: return y_quant.astype(np.float32)
    if not scale: return y_quant.astype(np.float32)
    return (y_quant.astype(np.float32) - zero) * scale

# ---------- load meta ----------
meta = json.load(open(META_PATH, "r"))
CLASSES = meta["classes"]                 # ['help','save_me','police']
SR      = int(meta["sample_rate"])        # e.g., 16000
WIN_S   = float(meta["window_s"])         # e.g., 1.2
N_MELS  = int(meta["n_mels"])             # e.g., 128

# ---------- collect test files ----------
pairs = []
for ci, cname in enumerate(CLASSES):
    cdir = os.path.join(TEST_ROOT, cname)
    if not os.path.isdir(cdir):
        print(f"WARNING: missing folder {cdir}")
        continue
    files = list_audio(cdir)
    if LIMIT_PER_CLASS:
        files = files[:LIMIT_PER_CLASS]
    pairs += [(f, ci) for f in files]

if not pairs:
    raise SystemExit("No test files found. Check TEST_ROOT and its subfolders (help/save_me/police).")

print("Counts per class:")
for cname in CLASSES:
    cdir = os.path.join(TEST_ROOT, cname)
    n = len(list_audio(cdir)) if os.path.isdir(cdir) else 0
    print(f"  {cname:<8s} : {n}")

# ---------- TFLite inference ----------
tflite = tf.lite
interp = tflite.Interpreter(model_path=MODEL_PATH)
interp.allocate_tensors()
in_det  = interp.get_input_details()
out_det = interp.get_output_details()

y_true, y_pred, probs_all, file_list = [], [], [], []
for fp, ci in pairs:
    spec = load_spec(fp, SR, WIN_S, N_MELS)
    x = ensure_bhwc1(spec).astype(np.float32)
    xq = quantize_input(x, in_det)
    interp.set_tensor(in_det[0]['index'], xq)
    interp.invoke()
    out = interp.get_tensor(out_det[0]['index'])
    p = np.squeeze(dequantize_output(out, out_det)).astype(np.float32)
    p = np.clip(p, 1e-6, 1.0); p /= p.sum()
    probs_all.append(p); y_true.append(ci); y_pred.append(int(np.argmax(p))); file_list.append(fp)

y_true = np.array(y_true, np.int32)
y_pred = np.array(y_pred, np.int32)
probs_all = np.vstack(probs_all)

# ---------- metrics ----------
acc = accuracy_score(y_true, y_pred)
cm  = confusion_matrix(y_true, y_pred)
prec, rec, f1, supp = precision_recall_fscore_support(y_true, y_pred, labels=range(len(CLASSES)))

print(f"\nAccuracy: {acc:.4f}\n")
print("Confusion Matrix (rows=true, cols=pred):\n", cm, "\n")
print("Classification Report:\n",
      classification_report(y_true, y_pred, target_names=CLASSES, digits=3))

# ---------- save per-file predictions ----------
df = pd.DataFrame({
    "file": file_list,
    "true": [CLASSES[i] for i in y_true],
    "pred": [CLASSES[i] for i in y_pred],
})
for j, cname in enumerate(CLASSES):
    df[f"prob_{cname}"] = probs_all[:, j]
csv_path = "/content/predictions.csv"
df.to_csv(csv_path, index=False)
print(f"\nSaved per-file predictions to: {csv_path}")
display(df.head(10))

# ---------- confusion matrix heatmap ----------
fig, ax = plt.subplots(figsize=(4.8,4.2), dpi=150)
im = ax.imshow(cm, cmap="Blues")
ax.set_title("Confusion Matrix")
ax.set_xlabel("Predicted")
ax.set_ylabel("True")
ax.set_xticks(range(len(CLASSES))); ax.set_xticklabels(CLASSES, rotation=15)
ax.set_yticks(range(len(CLASSES))); ax.set_yticklabels(CLASSES)
for i, j in product(range(cm.shape[0]), range(cm.shape[1])):
    ax.text(j, i, cm[i, j], ha="center", va="center", color="black")
plt.colorbar(im, fraction=0.046, pad=0.04)
plt.tight_layout()
plt.show()