# Integrating Audio Signal Processing and Machine Learning for Intelligent CCTV Emergency Dispatch
Traditional emergency dispatch systems frequently rely on human reporting or delayed interpretation which can result in slower and less reliable responses. We present an intelligent CCTV-based emergency dispatch framework to achieve a more rapid and reliable response which integrates real time audio signal processing and on-device speech recognition utilizing the Vosk Model Small (en-us-0.15), on a Raspberry Pi 4. The framework continually monitors the audio content of the environmental space in real time via a USB microphone and performs local inference to detect predetermined emergency keywords, e.g., "help", "save me", and "police". Once a keyword is detected, the system automatically activates the PiCamera2 live feed, captures the video context, and uploads metadata to Google Firebase Firestore. The uploaded metadata includes the detected keyword, slot number and timestamp, and once uploaded it becomes available for cloud-based remote (fire, police, ambulance) monitoring and dispatch. By performing the inference locally, and by design, the time from detection to alert is kept to a minimum and maintains continuity of operations for low or no connectivity. The framework combines edge computing, keyword-based speech, and a cloud-based logging solution to offer a low cost, scalable, and open to privacy based emergency safety framework. Performance of the system is evaluated based on detection accuracy, latency, and Firestore service, all indicating promise for real-time monitoring and safety automation.
